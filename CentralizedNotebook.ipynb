{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized prediction\n",
    "\n",
    "## Summary\n",
    "This file implements the classic way to do recommendation. This will help us ensure the recommendation results are the same that the decentralized way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from model.track_collection import TrackCollection\n",
    "from utils.collection_splitter import splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConfigurationÂ¶\n",
    "\n",
    "We created a way to extract rating of each track from a user's library. The probleme we faced is that we just have one real user's library. So we can't use it for the prediction (we need more users, and if we split the lib of this user in multiple libraries, it'll not be relevant because the rating will be the same). So we created a totally fake music library, and 5 users with a part of the global library and notation on it. You can find the details in files:\n",
    "\n",
    "    data/track_collection_test.json - The global library\n",
    "    data/users/i.json - The lib of the ith user\n",
    "\n",
    "So here in the config, the commented code is dynamic, but not relevant as we have just one real library. And the other code is hardcorded for the 5 test users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_USERS = 5\n",
    "\n",
    "### Loading the tracks data; and splitting them into number_of_users collections\n",
    "track_collection = TrackCollection()\n",
    "track_collection.load(os.path.join('data', 'track_collection_test.json'))\n",
    "df_track_collection = track_collection.to_dataframe()\n",
    "track_list = df_track_collection[['id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "since we are in a centralized configuration (one central server can have that listenning data and ratings of all users), we just merge all the tracks stats into one matrix, using the same id (we suppose here that the id of the track is given by the central track collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we merge the different users in one\n",
    "user_dfs = []\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    tc = TrackCollection()\n",
    "    tc.load(os.path.join('data', 'users', str(i+1)+'.json'))\n",
    "    ndf = tc.to_dataframe()[['id', 'rating_score']]\n",
    "    user_matrix = track_list.merge(ndf, on='id', how='left')\n",
    "    user_dfs.append(user_matrix[['id', 'rating_score']])\n",
    "    \n",
    "matrix = track_list\n",
    "for index, udf in enumerate(user_dfs):\n",
    "    matrix = matrix.merge(user_dfs[index], on='id', how='left').rename(columns = {'rating_score': 'user_' + str(index)})\n",
    "    \n",
    "matrix = matrix.drop('id', axis=1)\n",
    "matrix = matrix.filter(regex='^user_[0-9]+$')\n",
    "matrix = matrix.astype('float')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing\n",
    "Here build the normalized matrix. The elements that are with a \"NaN\" rating s are left as is, to keep them different from the elements that have a \"0.0\" rating due to normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalize_matrix(df):\n",
    "    df = copy.copy(df)\n",
    "    for index, line in df.iterrows():\n",
    "        sum = 0\n",
    "        n = 0\n",
    "        for el in line:\n",
    "            if not math.isnan(el):\n",
    "                sum += el\n",
    "                n += 1\n",
    "        if n != 0:\n",
    "            line_mean = sum / n\n",
    "        else:\n",
    "            line_mean = 0\n",
    "        for el_idx, el in enumerate(line):\n",
    "            if not math.isnan(el):\n",
    "                line[el_idx] = el - line_mean\n",
    "        df.loc[index] = line\n",
    "    return df\n",
    "\n",
    "n_matrix = compute_normalize_matrix(matrix)\n",
    "n_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity matrix\n",
    "Here we compute the similarity matrix, by using the cos measure on the normalized matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nan_vector(vector):\n",
    "    for el in vector:\n",
    "        if not math.isnan(el):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def cos_measure(df, index_x, index_y):\n",
    "    # If some normalized vector is full of NaN components, then no user have ever evaluated that track\n",
    "    # So it should be ranked at -Infinity\n",
    "    rx = df.iloc[index_x]\n",
    "    ry = df.iloc[index_y]\n",
    "    if is_nan_vector(rx) or is_nan_vector(ry):\n",
    "        return - math.inf\n",
    "    \n",
    "    rx = rx.fillna(0.0)\n",
    "    ry = ry.fillna(0.0)\n",
    "    sc = np.dot(rx, ry)\n",
    "    if (np.linalg.norm(rx) * np.linalg.norm(ry)) != 0.:\n",
    "        return sc / (np.linalg.norm(rx) * np.linalg.norm(ry))\n",
    "    return 0.0  # the norm could be 0.0 since we normalized\n",
    "\n",
    "\n",
    "def rating_mean(df, track_index):\n",
    "    track = df.iloc[track_index].fillna(0)\n",
    "    if np.count_nonzero(track) == 0:\n",
    "        return 0\n",
    "    return np.sum(track) / np.count_nonzero(track)\n",
    "\n",
    "height = n_matrix.shape[0]\n",
    "n_sim_matrix = np.empty((height, height))\n",
    "columns = n_matrix.index.values\n",
    "for i in range(height): # for each track\n",
    "    for j in range(height):\n",
    "        n_sim_matrix[i][j] = cos_measure(n_matrix, i, j)\n",
    "n_sim_matrix = pd.DataFrame(n_sim_matrix, columns=n_matrix.index.values)\n",
    "n_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the tracks\n",
    "Here we compute the predicted rating for some track and check for each track that the user does not have in his own collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the weighted average\n",
    "def predict(df, sim_matrix, element_index, user_index):\n",
    "    user_col = df.iloc[:, user_index]\n",
    "\n",
    "    upper_sum = 0\n",
    "    lower_sum = 0\n",
    "    for index, el in enumerate(sim_matrix.iloc[:, element_index]):\n",
    "        if el >= 0 and el <= 0.99 and not math.isnan(el) and not math.isnan(user_col[index]):\n",
    "            upper_sum += el * user_col[index]\n",
    "            lower_sum += el\n",
    "    if lower_sum == 0:\n",
    "        return - math.inf\n",
    "    return upper_sum / lower_sum\n",
    "\n",
    "\n",
    "# we compute the predictions\n",
    "userToPredict = []\n",
    "userToPredict.append([2,3,4,5,6,10,11,14,15,18])\n",
    "userToPredict.append([0,2,3,8,12,13,14,18,19])\n",
    "userToPredict.append([2,3,4,5,6,7,10,12,13,14,15,17,19])\n",
    "userToPredict.append([2,3,7,8,9,10,12,13,14,15,16])\n",
    "userToPredict.append([1,2,4,5,6,7,8,9,10])\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(20):\n",
    "        if predict(matrix, n_sim_matrix, j, i) > rating_mean(matrix, j) and j in userToPredict[i]:\n",
    "            print(\"user_{} should listen music {}\".format(i, j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
